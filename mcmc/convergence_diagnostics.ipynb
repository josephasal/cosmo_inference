{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2IBYAT6bOLiRkqXDBDew7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephasal/cosmo_inference/blob/adaptive_cov/mcmc/convergence_diagnostics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC55v4bene2-"
      },
      "outputs": [],
      "source": [
        "#Gelman-Rubin diagnostic\n",
        "\n",
        "def gelman_rubin(chains):\n",
        "  \"\"\"\n",
        "  Function that uses the Gelman-Rubin diagnostic test for convergence, compares variance between multiple chains to the variance within each chain\n",
        "\n",
        "  input: 2d array of the chain for a particular parameter (rows = value of parameter at iteration, column = walker )\n",
        "\n",
        "  output: Estimate of R\n",
        "\n",
        "  \"\"\"\n",
        "  #Mean of each chain\n",
        "  chain_means = np.mean(chains, axis=0) #mean of parameters at each point\n",
        "\n",
        "\n",
        "  #Overall mean of all the chains across the whole thing\n",
        "  overall_mean = np.mean(chain_means)\n",
        "\n",
        "  #Between chain variance\n",
        "  n, m = chains.shape\n",
        "  B = (n/(m-1)) * np.sum((chain_means - overall_mean)**2) #lmao this was giving such a weird B value at first because it was summing before squaring, fixed with brackets now\n",
        "\n",
        "  #Average chain variance\n",
        "  W = 1/(m) * np.sum(np.var(chains, axis = 0, ddof = 1))\n",
        "\n",
        "  #Calculate V\n",
        "  V = ((n-1)/n) * W + ((m+1)/(m*n)) * B\n",
        "\n",
        "  #Calculate R\n",
        "  R = np.sqrt(V/W)\n",
        "\n",
        "  return R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Want to compare my MCMC code to emcee so going to use ESS to do so as we cannot use Gelman Rubin diagnostic on emcee because the chains are not independent\n",
        "\n",
        "#Effective sample size\n",
        "\n",
        "def autocorrelation(x, lag):\n",
        "\n",
        "  \"\"\"\n",
        "  Calulcated the autocorrelation of array x at a given lag k\n",
        "  Auto correlation is covariance(X,Y) over standard deviation\n",
        "  \"\"\"\n",
        "  n = len(x)\n",
        "  covariance = np.sum((x[:n-lag] - np.mean(x)) * (x[lag:] - np.mean(x)))\n",
        "  std = np.sum((x - np.mean(x))**2)\n",
        "  return covariance/std\n",
        "\n",
        "def eff_sample_size(chain):\n",
        "  \"\"\"\n",
        "  Calculates effective sample size, estimate of sample size that is not related\n",
        "\n",
        "  inputs: chain of samples from mcmc\n",
        "\n",
        "  outputs: effective sample size, number\n",
        "  \"\"\"\n",
        "  #Need to do N divided by sum of lag from -inf to inf which simplifies to 1+2* of lag from 1 to T (first odd positive intger for which autocorrelation of that t+1 and t+2 are negative)\n",
        "  #From chapter 11 in BDA3\n",
        "  #just gonna use N//2 which is a common implementation for the sum\n",
        "\n",
        "  N = len(chain)\n",
        "\n",
        "  rho_sum = 0\n",
        "  previous_rho = 0\n",
        "  for i in range(1,N//2):\n",
        "    rho_t = autocorrelation(chain, i)\n",
        "\n",
        "    #Stop summing when pt+1 and pt+2 are negative\n",
        "    if i > 1 and (rho_t + previous_rho) < 0:\n",
        "      break\n",
        "\n",
        "    rho_sum += rho_t\n",
        "    previous_rho = rho_t #to go loop back for the comparison\n",
        "\n",
        "  ess = N / (1 + 2 * rho_sum)\n",
        "\n",
        "  return ess\n",
        "\n",
        "#Well turns out this only does it for one chain rip, but i can use it to calculaurte all the chains ess shown in the next cell"
      ],
      "metadata": {
        "id": "a_ZmvprExwQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#real ess calculator\n",
        "\n",
        "def eff_sample_size_multichain(chains):\n",
        "\n",
        "  \"\"\"\n",
        "  Calculated the total effective sample size by using all the chains this time\n",
        "\n",
        "  Inputs:\n",
        "  chains: array in the shape of (iterations, n_walker)\n",
        "\n",
        "  outputs:\n",
        "  total_ess: a number that says the effective sample size of all the chains\n",
        "  \"\"\"\n",
        "  n_chains = chains.shape[1] #y column of chains array\n",
        "  ess_values = [eff_sample_size(chains[:,i]) for i in range(n_chains)] #calculate ess for each chain\n",
        "  total_ess = sum(ess_values) #add up all the chains ess to get one big final ess\n",
        "  return total_ess"
      ],
      "metadata": {
        "id": "B_zoLOztazbq"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}