{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPECGprjMDUxvipE8gGBILi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephasal/cosmo_inference/blob/diagnostics-%2B-adaptive-sampling/mcmc/convergence_diagnostics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "TC55v4bene2-"
      },
      "outputs": [],
      "source": [
        "#Gelman-Rubin diagnostic\n",
        "\n",
        "def gelman_rubin(chains):\n",
        "  \"\"\"\n",
        "  Function that uses the Gelman-Rubin diagnostic test for convergence, compares variance between multiple chains to the variance within each chain\n",
        "\n",
        "  input: 2d array of the chain for a particular parameter (rows = value of parameter at iteration, column = walker )\n",
        "\n",
        "  output: Estimate of R\n",
        "\n",
        "  \"\"\"\n",
        "  #Mean of each chain\n",
        "  chain_means = np.mean(chains, axis=0) #mean of parameters at each point\n",
        "\n",
        "\n",
        "  #Overall mean of all the chains across the whole thing\n",
        "  overall_mean = np.mean(chain_means)\n",
        "\n",
        "  #Between chain variance\n",
        "  n, m = chains.shape\n",
        "  B = (n/(m-1)) * np.sum((chain_means - overall_mean)**2) #lmao this was giving such a weird B value at first because it was summing before squaring, fixed with brackets now\n",
        "\n",
        "  #Average chain variance\n",
        "  W = 1/(m) * np.sum(np.var(chains, axis = 0, ddof = 1))\n",
        "\n",
        "  #Calculate V\n",
        "  V = ((n-1)/n) * W + ((m+1)/(m*n)) * B\n",
        "\n",
        "  #Calculate R\n",
        "  R = np.sqrt(V/W)\n",
        "\n",
        "  return R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Want to compare my MCMC code to emcee so going to use ESS to do so as we cannot use Gelman Rubin diagnostic on emcee because the chains are not independent\n",
        "\n",
        "#Effective sample size\n",
        "\n",
        "def autocorrelation(x, lag):\n",
        "\n",
        "  \"\"\"\n",
        "  Calulcated the autocorrelation of array x at a given lag k\n",
        "  Auto correlation is covariance(X,Y) over standard deviation\n",
        "  \"\"\"\n",
        "  n = len(x)\n",
        "  covariance = np.sum((x[:n-lag] - np.mean(x) * (x[lag:] - np.mean(x))))\n",
        "  std = np.sum((x - np.mean(x))**2)\n",
        "  return covariance/std\n",
        "\n",
        "def eff_sample_size(chain):\n",
        "  \"\"\"\n",
        "  Calculates effective sample size, estimate of sample size that is not related\n",
        "\n",
        "  inputs: chain of samples from mcmc\n",
        "\n",
        "  outputs: effective sample size, number\n",
        "  \"\"\"\n",
        "  #Need to do N divided by sum of lag from -inf to inf which simplifies to 1+2* of lag from 1 to T (first odd positive intger for which autocorrelation of that t+1 and t+2 are negative)\n",
        "  #From chapter 11 in BDA3\n",
        "  #just gonna use N//2 which is a common implementation for the sum\n",
        "\n",
        "  N = len(chain)\n",
        "\n",
        "  rho_sum = 0\n",
        "\n",
        "  for i in range(1,N//2):\n",
        "    rho_t = autocorrelation(chain, i)\n",
        "\n",
        "    #Stop summing when pt+1 and pt+2 are negative\n",
        "    if i > 1 and (rho_t + previous_rho) < 0:\n",
        "      break\n",
        "\n",
        "    rho_sum += rho_t\n",
        "    previous_rho = rho_t #to go loop back for the comparison\n",
        "\n",
        "  ess = N / (1 + 2 * rho_sum)\n",
        "\n",
        "  print(f\"Effective Sample Size (ESS) = {ess:.2f}\")\n",
        "\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "id": "a_ZmvprExwQy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_zoLOztazbq"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}