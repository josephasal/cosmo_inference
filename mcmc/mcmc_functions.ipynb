{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUoeT3nn7+iqmIc0eC3pFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephasal/cosmo_inference/blob/main/mcmc/mcmc_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file has all the code for the functions:\n",
        "* Distance modulus + fitting function\n",
        "* log likelihood and prior\n",
        "* basic & adaptive mcmc\n",
        "* Convergence via Gellman Rubin diagnostic\n",
        "* Autocorrelation\n",
        "* Effective sample size"
      ],
      "metadata": {
        "id": "KBfB-Fly-kUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distance Modulus + Fitting function\n"
      ],
      "metadata": {
        "id": "4BEZ-ei8_dIL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oonddJup-Rr7"
      },
      "outputs": [],
      "source": [
        "#Dimensionless distance modulus function implementation\n",
        "\n",
        "#Distance modulus function\n",
        "def calculate_distance_modulus(z, omega_m,h):\n",
        "  \"\"\"\n",
        "  Calculates dimensionless theoretical distance modulus using\n",
        "\n",
        "  inputs:\n",
        "   - z: Redshift\n",
        "   - omega_m: density matter parameter\n",
        "   - h: dimensionless hubble constance H0 = 100h km/s/Mpc\n",
        "\n",
        "   outputs: theoretical distance modulus\n",
        "  \"\"\"\n",
        "  c = 299792.458   # speed of light in km/s\n",
        "  H0 = 100 * h     # Hubble constant in km/s/Mpc\n",
        "\n",
        "  #Luminosity distance based on Penn 1999 analytic solution\n",
        "\n",
        "  #Fitting function\n",
        "  def eta(a,omega_m):\n",
        "    \"\"\"\n",
        "    Fits eta\n",
        "    inputs:\n",
        "      a - a number\n",
        "      omega_m - matter density\n",
        "\n",
        "    outputs: eta as a function of a and omega_m\n",
        "    \"\"\"\n",
        "    s = ((1-omega_m)/omega_m)**(1/3)\n",
        "    eta = 2*np.sqrt(s**3 +1) * ((1/(a**4)) - 0.1540*(s/(a**3)) + 0.4304 *((s**2)/(a**2)) + 0.19097*((s**3)/a) + 0.066941*(s**4))**(-1/8)\n",
        "\n",
        "    return eta\n",
        "\n",
        "  #Calculate eta for 1 and 1/z+1\n",
        "  a = 1/(z+1)\n",
        "  eta_1 = eta(1,omega_m)\n",
        "  eta_z = np.array([eta(ai, omega_m) for ai in a])\n",
        "\n",
        "  #Dimensionless luminosity distance calculation\n",
        "  d_L_star = (c/H0) * (1+z) * (eta_1 - eta_z)\n",
        "\n",
        "\n",
        "\n",
        "  #Now to calculate distance modulus mu\n",
        "  theoretical_mu = 25 + 5*np.log10(d_L_star)\n",
        "  return theoretical_mu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Likelihood and Prior"
      ],
      "metadata": {
        "id": "DFHC16uW_hFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Likelihood function, standard gaussian function\n",
        "\n",
        "def log_likelihood(mu_obs, mu_model, sigma_mu):\n",
        "\n",
        "  \"\"\"\n",
        "  Computes thes logged likelihood for the sample and observed distance modulus\n",
        "\n",
        "  inputs:\n",
        "    - mu_obs: observed mu (mu from the data)\n",
        "    - mu_model: theoretical mu from the model\n",
        "    - sigma_mu: standard deviation of the observed mu (uncertainty)\n",
        "\n",
        "  outputs:\n",
        "    - log likelihood\n",
        "\n",
        "  \"\"\"\n",
        "  return -0.5 * np.sum((mu_obs - mu_model)**2/sigma_mu**2)\n",
        "\n",
        "\n",
        "# Defining the prior as a function\n",
        "def log_prior(params):\n",
        "  \"\"\"\n",
        "  Function that sets a uniform prior of omega m and h\n",
        "\n",
        "  \"\"\"\n",
        "  omega_m, h = params\n",
        "  if 0.1 < omega_m < 0.5 and 0.4 < h < 0.9:\n",
        "    return 0.0\n",
        "\n",
        "  else:\n",
        "    return -np.inf #acceptance probability is 0 if not in the priors upper and lower bounds"
      ],
      "metadata": {
        "id": "nz5HfiF1_kWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic MCMC"
      ],
      "metadata": {
        "id": "Lk63WXFY_myz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Metropolis Hastings algorithm\n",
        "\n",
        "def metropolis_hastings(likelihood, z, mu_obs, sigma_mu, n_steps, initial_params, step_size, burn_in, n_walkers):\n",
        "  \"\"\"\n",
        "  Perform Metropolis Hastings MCMC to sample from the posterior\n",
        "\n",
        "  inputs:\n",
        "    - likelihood: function to compute the likelihood\n",
        "    - z: redshift\n",
        "    - mu_obs: observed mu\n",
        "    - sigma_mu: standard deviation of the observed mu\n",
        "    - n_steps: Number of steps for MCMC\n",
        "    - intial_params: initial guesses for [omega_m, h] for each walker, has to be array with rows = number of walkers\n",
        "    - step size: proposal step size for [omega_m, h]\n",
        "    - burn_in : percentage of chain to discard for the burn in period (given as a decimal)\n",
        "    - n_walkers: number of walkers that are sampling\n",
        "\n",
        "  outputs:\n",
        "  Array of 3 dimensions, in shape of (steps after burn in , walker number, 2)\n",
        "\n",
        "  \"\"\"\n",
        "  params = np.array(initial_params) #input as [] bracket so just make an array\n",
        "  samples = []\n",
        "  accepted_samples = np.zeros(n_walkers) #gonna use to calculate acceptance rate\n",
        "\n",
        "  for step in range (n_steps):\n",
        "    new_params = np.empty_like(params) #empty array same size as intial parameters array, need to keep track of new paramters for each walker via matrix\n",
        "\n",
        "    #Do similar calulation for new parameters as before but just have to loop it for all walkers now\n",
        "    for i in range(n_walkers):\n",
        "\n",
        "      #Proposal\n",
        "      #guess for new parameters, propsal distribution is a multivariate gaussian distribution now\n",
        "      #Step size has to be a 2x1 array\n",
        "      sigma_omega_m = step_size[0]\n",
        "      sigma_h = step_size[1]\n",
        "\n",
        "      #covariance matrix thing off diagonals are the correlation between the values\n",
        "      rho = 0 #set as 0 assume no correlation between the parameters\n",
        "      covariance_matrix = np.array([[sigma_omega_m**2, rho], [rho, sigma_h**2]])\n",
        "\n",
        "      #drawing from this new proposal now but for each walker/ walker i\n",
        "      proposed_params = params[i] + np.random.multivariate_normal(np.zeros(2), covariance_matrix)\n",
        "      omega_m_proposed, h_proposed = proposed_params\n",
        "\n",
        "      # Priors on Omega_m and h, using our new functions\n",
        "      log_prior_proposed = log_prior(proposed_params)\n",
        "\n",
        "      #If prior is  - infininty then proposal out of bounds so reject\n",
        "      if np.isneginf(log_prior_proposed):\n",
        "        new_params[i] = params[i]\n",
        "        continue\n",
        "\n",
        "      #Distance modulus and log likelihood of proposed parameters\n",
        "      proposed_mu_model = calculate_distance_modulus(z, proposed_params[0], proposed_params[1]) #now for each walker\n",
        "      proposed_log_likelihood = log_likelihood(mu_obs, proposed_mu_model, sigma_mu)\n",
        "\n",
        "\n",
        "      #Posterior for proposed parameters\n",
        "      proposed_log_posterior = proposed_log_likelihood + log_prior_proposed\n",
        "\n",
        "      #Distance modulus, log likelihood and posterior of current parameters, initially inputted from the function\n",
        "      current_mu_model = calculate_distance_modulus(z, params[i,0], params[i,1])  #now for each walker\n",
        "      current_log_likelihood = log_likelihood(mu_obs, current_mu_model, sigma_mu)\n",
        "      current_log_posterior = current_log_likelihood + log_prior(params[i])\n",
        "\n",
        "      #Calculate the acceptance probability, now based on log posteriors\n",
        "      delta_log_posterior = proposed_log_posterior - current_log_posterior\n",
        "\n",
        "      #Implementing explicit overflow protection\n",
        "      #If the difference in likelihoods is at max python limit, then accept the new proposal with probaiblity 1. Means new parameters are leng\n",
        "      if delta_log_posterior > 700:\n",
        "        acceptance_probability = 1.0\n",
        "\n",
        "      #If difference in likelihood is at min python limit, then dont accept the new proposal at all. Means new parameters are clapped\n",
        "      elif delta_log_posterior < -700:\n",
        "        acceptance_probability = 0.0\n",
        "\n",
        "      #If difference something else then we accept with probability below and randomly sample. Lets us explore parameter space\n",
        "      else:\n",
        "        acceptance_probability = min(1, np.exp(delta_log_posterior))\n",
        "\n",
        "\n",
        "      u = np.random.uniform(0,1) #set the randomness part of accept/ reject\n",
        "\n",
        "      #Accept proposed move\n",
        "      if u < acceptance_probability:\n",
        "        new_params[i] = proposed_params\n",
        "        accepted_samples[i] += 1\n",
        "      else:\n",
        "        new_params[i] = params[i] #chain doesnt move and retrys sampling\n",
        "\n",
        "    #Updating all the walkers at the same time, outside of the loop, do end of every loop\n",
        "    params = new_params.copy()\n",
        "    samples.append(params.copy())\n",
        "\n",
        "  #Acceptance ratio calculation\n",
        "  acceptance_ratio = accepted_samples/ n_steps\n",
        "  print(f\"MCMC carried out with {n_steps} steps, and acceptance ratio of each walker {acceptance_ratio}\")\n",
        "\n",
        "\n",
        "  #Number of samples to discard from the chain due to burn in\n",
        "  burned_chains = int(burn_in * n_steps) #keep integer\n",
        "  samples_post_burn = samples[burned_chains:] #use everything after the burn in number\n",
        "\n",
        "  return np.array(samples_post_burn)\n",
        "\n"
      ],
      "metadata": {
        "id": "zz7BuxlV_o_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptive MCMC"
      ],
      "metadata": {
        "id": "R4sdLhlV_0iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Adaptive Metropolis Hastings algorithm\n",
        "\n",
        "def adaptive_metropolis_hastings(likelihood, z, mu_obs, sigma_mu, n_steps, initial_params, step_size, burn_in, n_walkers, update_interval, target_alpha, learning_rate):\n",
        "  \"\"\"\n",
        "  Perform Metropolis Hastings MCMC to sample from the posterior\n",
        "\n",
        "  inputs:\n",
        "    - likelihood: function to compute the likelihood\n",
        "    - z: redshift\n",
        "    - mu_obs: observed mu\n",
        "    - sigma_mu: standard deviation of the observed mu\n",
        "    - n_steps: Number of steps for MCMC\n",
        "    - intial_params: initial guesses for [omega_m, h] for each walker, has to be array with rows = number of walkers\n",
        "    - step size: proposal step size for [omega_m, h]\n",
        "    - burn_in : percentage of chain to discard for the burn in period (given as a decimal)\n",
        "    - n_walkers: number of walkers that are sampling\n",
        "    - update_interval: number of iterations to update the adaptive parameters\n",
        "    - target_alpha: target acceptance rate\n",
        "    - learning_rate: learning rate of the adaptation\n",
        "\n",
        "\n",
        "  outputs:\n",
        "  - Array of 3 dimensions, in shape of (steps after burn in , walker number, 2)\n",
        "  - Alpha all walkers: average acceptance rate of the whole thing\n",
        "\n",
        "  \"\"\"\n",
        "  params = np.array(initial_params) #input as [] bracket so just make an array\n",
        "  samples = []\n",
        "  accepted_samples = np.zeros(n_walkers) #gonna use to calculate acceptance rate\n",
        "\n",
        "  #New adaptive parameters:\n",
        "\n",
        "  accepted_cycle = np.zeros(n_walkers)  #empty array of accepted proposals at each cycle/iteration\n",
        "\n",
        "\n",
        "  #Proposal\n",
        "  #guess for new parameters, propsal distribution is a multivariate gaussian distribution now\n",
        "  #Step size has to be a 2x1 array\n",
        "  sigma_omega_m = step_size[0]\n",
        "  sigma_h = step_size[1]\n",
        "\n",
        "  #Initialise covariance matrix\n",
        "  #intially set correlation as 0\n",
        "\n",
        "  covariance_matrix = np.array([[sigma_omega_m**2, 0], [0, sigma_h**2]])\n",
        "\n",
        "  #add smoothing parameter when updating the covariance matrix later, so that we dont just abruptly jump fully to the new one\n",
        "  smoothing = 0.2 #keeps 80% of the old covariance, can adjust this later\n",
        "\n",
        "  #Lists to store the history of the covariance and step size: used to test the pilot runs\n",
        "  cov_history = []\n",
        "  step_history = []\n",
        "\n",
        "  for step in range (n_steps):\n",
        "    new_params = np.empty_like(params) #empty array same size as intial parameters array, need to keep track of new paramters for each walker via matrix\n",
        "\n",
        "    #Do similar calulation for new parameters as before but just have to loop it for all walkers now\n",
        "    for i in range(n_walkers):\n",
        "\n",
        "\n",
        "      #drawing from the new proposal now but for each walker/ walker i\n",
        "      proposed_params = params[i] + np.random.multivariate_normal(np.zeros(2), covariance_matrix)\n",
        "\n",
        "      # Priors on Omega_m and h, using our new functions\n",
        "      log_prior_proposed = log_prior(proposed_params)\n",
        "\n",
        "      #If prior is  - infininty then proposal out of bounds so reject\n",
        "      if np.isneginf(log_prior_proposed):\n",
        "        new_params[i] = params[i]\n",
        "        continue\n",
        "\n",
        "      #Distance modulus and log likelihood of proposed parameters\n",
        "      proposed_mu_model = calculate_distance_modulus(z, proposed_params[0], proposed_params[1]) #now for each walker\n",
        "      proposed_log_likelihood = log_likelihood(mu_obs, proposed_mu_model, sigma_mu)\n",
        "\n",
        "\n",
        "      #Posterior for proposed parameters\n",
        "      proposed_log_posterior = proposed_log_likelihood + log_prior_proposed\n",
        "\n",
        "      #Distance modulus, log likelihood and posterior of current parameters, initially inputted from the function\n",
        "      current_mu_model = calculate_distance_modulus(z, params[i,0], params[i,1])  #now for each walker\n",
        "      current_log_likelihood = log_likelihood(mu_obs, current_mu_model, sigma_mu)\n",
        "      current_log_posterior = current_log_likelihood + log_prior(params[i])\n",
        "\n",
        "      #Calculate the acceptance probability, now based on change of log posteriors\n",
        "      delta_log_posterior = proposed_log_posterior - current_log_posterior\n",
        "\n",
        "      #Implementing explicit overflow protection\n",
        "      #If the difference in likelihoods is at max python limit, then accept the new proposal with probaiblity 1. Means new parameters are leng\n",
        "      if delta_log_posterior > 700:\n",
        "        acceptance_probability = 1.0\n",
        "\n",
        "      #If difference in likelihood is at min python limit, then dont accept the new proposal at all. Means new parameters are clapped\n",
        "      elif delta_log_posterior < -700:\n",
        "        acceptance_probability = 0.0\n",
        "\n",
        "      #If difference something else then we accept with probability below and randomly sample. Lets us explore parameter space\n",
        "      else:\n",
        "        acceptance_probability = min(1, np.exp(delta_log_posterior))\n",
        "\n",
        "\n",
        "      u = np.random.uniform(0,1) #set the randomness part of accept/ reject\n",
        "\n",
        "      #Accept proposed move\n",
        "      if u < acceptance_probability:\n",
        "        new_params[i] = proposed_params\n",
        "        accepted_samples[i] += 1\n",
        "        accepted_cycle[i] += 1 #also add acceptance count for each walker adaptation thing\n",
        "      else:\n",
        "        new_params[i] = params[i] #chain doesnt move and retrys sampling\n",
        "\n",
        "    #Updating all the walkers at the same time, outside of the loop, do end of every loop\n",
        "    params = new_params.copy()\n",
        "    samples.append(params.copy())\n",
        "\n",
        "    #Adaptive update of covariance after every update interval iteration loop\n",
        "    if (step +1) % update_interval == 0: #check if nth+1 iteration is exact multiple, so saying it has don 100/200/300 steps\n",
        "      average_acceptance = np.mean(accepted_cycle)/ update_interval #acceptance rate of this cycle (100 steps)\n",
        "\n",
        "      #Use the last update interval to calculate the variance\n",
        "      recent_window = samples[-update_interval:]\n",
        "      recent_samples = np.array(recent_window).reshape(-1,2) #make it 2d\n",
        "\n",
        "      #Calculate sample covariance and this then includes if there are any correlations between them in the off diagonals\n",
        "      sample_cov = np.cov(recent_samples, rowvar = False)\n",
        "      epsilon = 1e-6\n",
        "      sample_cov += epsilon *np.eye(2)\n",
        "\n",
        "      #Scale covariance based on acceptance rate difference\n",
        "      #Increase covariance matrix if alpha larger than target, decrease if alpha is too small\n",
        "      #Robbins Munro approximation/ Haario et al.\n",
        "\n",
        "      scale_factor = np.exp(learning_rate * (average_acceptance - target_alpha))\n",
        "      new_covariance_matrix = sample_cov * scale_factor\n",
        "\n",
        "\n",
        "      #update the proposal covariance and then adjust step size using the sqrt of the diagonals of the covariance matrix\n",
        "      #Add smoothing to the update now\n",
        "      covariance_matrix = (1-smoothing) * covariance_matrix + smoothing * new_covariance_matrix\n",
        "\n",
        "      step_size = [np.sqrt(covariance_matrix[0,0]), np.sqrt(covariance_matrix[1,1])]\n",
        "\n",
        "      #Saving copies of the covariance and step size to look at when testing the pilot runs\n",
        "      cov_history.append(covariance_matrix.copy())\n",
        "      step_history.append(step_size.copy())\n",
        "\n",
        "      #Reset counter\n",
        "      accepted_cycle = np.zeros(n_walkers)\n",
        "\n",
        "  #Acceptance ratio calculation\n",
        "  acceptance_ratio = accepted_samples/ n_steps\n",
        "\n",
        "\n",
        "  #Return avergae acceptance ratio of all the walkers\n",
        "  alpha_all_walkers = np.mean(acceptance_ratio)\n",
        "\n",
        "  print(f\"MCMC carried out with {n_steps} steps, and average acceptance rate of each walker {alpha_all_walkers}\")\n",
        "\n",
        "  #Number of samples to discard from the chain due to burn in\n",
        "  burned_chains = int(burn_in * n_steps) #keep integer\n",
        "  samples_post_burn = samples[burned_chains:] #use everything after the burn in number\n",
        "\n",
        "  return np.array(samples_post_burn), alpha_all_walkers, cov_history, step_history\n",
        "\n"
      ],
      "metadata": {
        "id": "JYsz56vJ_2e-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gelman Rubin Diagnostic"
      ],
      "metadata": {
        "id": "VjDbJIy5_7FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gelman_rubin(chains):\n",
        "  \"\"\"\n",
        "  Function that uses the Gelman-Rubin diagnostic test for convergence, compares variance between multiple chains to the variance within each chain\n",
        "\n",
        "  input: 2d array of the chain for a particular parameter (rows = value of parameter at iteration, column = walker )\n",
        "\n",
        "  output: Estimate of R\n",
        "\n",
        "  \"\"\"\n",
        "  #Mean of each chain\n",
        "  chain_means = np.mean(chains, axis=0) #mean of parameters at each point\n",
        "\n",
        "\n",
        "  #Overall mean of all the chains across the whole thing\n",
        "  overall_mean = np.mean(chain_means)\n",
        "\n",
        "  #Between chain variance\n",
        "  n, m = chains.shape\n",
        "  B = (n/(m-1)) * np.sum((chain_means - overall_mean)**2) #lmao this was giving such a weird B value at first because it was summing before squaring, fixed with brackets now\n",
        "\n",
        "  #Average chain variance\n",
        "  W = 1/(m) * np.sum(np.var(chains, axis = 0, ddof = 1))\n",
        "\n",
        "  #Calculate V\n",
        "  V = ((n-1)/n) * W + ((m+1)/(m*n)) * B\n",
        "\n",
        "  #Calculate R\n",
        "  R = np.sqrt(V/W)\n",
        "\n",
        "  return R"
      ],
      "metadata": {
        "id": "UM-T0d9G_9Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto correlation"
      ],
      "metadata": {
        "id": "IZN-UTez__LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def autocorrelation(x, lag):\n",
        "\n",
        "  \"\"\"\n",
        "  Calulcated the autocorrelation of array x at a given lag k\n",
        "  Auto correlation is covariance(X,Y) over standard deviation\n",
        "  \"\"\"\n",
        "  n = len(x)\n",
        "  covariance = np.sum((x[:n-lag] - np.mean(x)) * (x[lag:] - np.mean(x)))\n",
        "  std = np.sum((x - np.mean(x))**2)\n",
        "  return covariance/std"
      ],
      "metadata": {
        "id": "nIwRSilyABbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Effective sample size"
      ],
      "metadata": {
        "id": "DVkzqyyIAIuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eff_sample_size(chain):\n",
        "  \"\"\"\n",
        "  Calculates effective sample size, estimate of sample size that is not related\n",
        "\n",
        "  inputs: chain of samples from mcmc\n",
        "\n",
        "  outputs: effective sample size, number\n",
        "  \"\"\"\n",
        "  #Need to do N divided by sum of lag from -inf to inf which simplifies to 1+2* of lag from 1 to T (first odd positive intger for which autocorrelation of that t+1 and t+2 are negative)\n",
        "  #From chapter 11 in BDA3\n",
        "  #just gonna use N//2 which is a common implementation for the sum\n",
        "\n",
        "  N = len(chain)\n",
        "\n",
        "  rho_sum = 0\n",
        "  previous_rho = 0\n",
        "  for i in range(1,N//2):\n",
        "    rho_t = autocorrelation(chain, i)\n",
        "\n",
        "    #Stop summing when pt+1 and pt+2 are negative\n",
        "    if i > 1 and (rho_t + previous_rho) < 0:\n",
        "      break\n",
        "\n",
        "    rho_sum += rho_t\n",
        "    previous_rho = rho_t #to go loop back for the comparison\n",
        "\n",
        "  ess = N / (1 + 2 * rho_sum)\n",
        "\n",
        "  return ess\n",
        "\n",
        "#Well turns out this only does it for one chain rip, but i can use it to calculaurte all the chains ess shown in the next cell\n",
        "\n",
        "#real ess calculator\n",
        "\n",
        "def eff_sample_size_multichain(chains):\n",
        "\n",
        "  \"\"\"\n",
        "  Calculated the total effective sample size by using all the chains this time\n",
        "\n",
        "  Inputs:\n",
        "  chains: array in the shape of (iterations, n_walker)\n",
        "\n",
        "  outputs:\n",
        "  total_ess: a number that says the effective sample size of all the chains\n",
        "  \"\"\"\n",
        "  n_chains = chains.shape[1] #y column of chains array\n",
        "  ess_values = [eff_sample_size(chains[:,i]) for i in range(n_chains)] #calculate ess for each chain\n",
        "  total_ess = sum(ess_values) #add up all the chains ess to get one big final ess\n",
        "  return total_ess\n"
      ],
      "metadata": {
        "id": "R4eccXZQAE4n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}