{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1w80u-YiBkjAB_HhfDvUM_yqGdmPxxCa6",
      "authorship_tag": "ABX9TyM+LRufmUwATkQCN+H9PYVx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephasal/cosmo_inference/blob/main/neural_network/simulating_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used to generate training data, using same exact functions defined before"
      ],
      "metadata": {
        "id": "GEJodQXIH_65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xx7TeyTZGNu3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#Dimensionless distance modulus function implementation\n",
        "\n",
        "#Distance modulus function\n",
        "def calculate_distance_modulus(z, omega_m,h):\n",
        "  \"\"\"\n",
        "  Calculates dimensionless theoretical distance modulus using\n",
        "\n",
        "  inputs:\n",
        "   - z: Redshift\n",
        "   - omega_m: density matter parameter\n",
        "   - h: dimensionless hubble constance H0 = 100h km/s/Mpc\n",
        "\n",
        "   outputs: theoretical distance modulus\n",
        "  \"\"\"\n",
        "  c = 299792.458   # speed of light in km/s\n",
        "  H0 = 100 * h     # Hubble constant in km/s/Mpc\n",
        "\n",
        "  #Luminosity distance based on Penn 1999 analytic solution\n",
        "\n",
        "  #Fitting function\n",
        "  def eta(a,omega_m):\n",
        "    \"\"\"\n",
        "    Fits eta\n",
        "    inputs:\n",
        "      a - a number\n",
        "      omega_m - matter density\n",
        "\n",
        "    outputs: eta as a function of a and omega_m\n",
        "    \"\"\"\n",
        "    s = ((1-omega_m)/omega_m)**(1/3)\n",
        "    eta = 2*np.sqrt(s**3 +1) * ((1/(a**4)) - 0.1540*(s/(a**3)) + 0.4304 *((s**2)/(a**2)) + 0.19097*((s**3)/a) + 0.066941*(s**4))**(-1/8)\n",
        "\n",
        "    return eta\n",
        "\n",
        "  #Calculate eta for 1 and 1/z+1\n",
        "  a = 1/(z+1)\n",
        "  eta_1 = eta(1,omega_m)\n",
        "  eta_z = np.array([eta(ai, omega_m) for ai in a])\n",
        "\n",
        "  #Dimensionless luminosity distance calculation\n",
        "  d_L_star = (c/H0) * (1+z) * (eta_1 - eta_z)\n",
        "\n",
        "\n",
        "\n",
        "  #Now to calculate distance modulus mu\n",
        "  theoretical_mu = 25 + 5*np.log10(d_L_star)\n",
        "  return theoretical_mu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Input X is distance modulus for various z values\n",
        "* Output Y is pair of parameters [omega_m,h]"
      ],
      "metadata": {
        "id": "nbUPKypwN4TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training data generation\n",
        "\n",
        "#how many samples i want\n",
        "training_samples = 10000\n",
        "\n",
        "#setting ranges for omega m and h based on values that are plausible (from planck 2018)\n",
        "omega_m_samples = np.random.uniform(0.1,0.5, training_samples)\n",
        "h_samples = np.random.uniform(0.4,0.9, training_samples)\n",
        "\n",
        "#grid of redshift values\n",
        "redshifts = np.linspace(0.01,1,100)\n",
        "\n",
        "#calulcating distance moudulus for each parameter across the 100 redshift values\n",
        "mu = []\n",
        "for omega_m_i, hi in zip(omega_m_samples, h_samples):\n",
        "  mu_vector = calculate_distance_modulus(redshifts, omega_m_i, hi)\n",
        "  mu.append(mu_vector)\n",
        "\n",
        "#Definfing training examples:\n",
        "\n",
        "#converting list into numpy array\n",
        "X_train = np.array(mu)\n",
        "\n",
        "#use numpy column stack to take the two arrays and put them side by side, first column is omega m second column is h\n",
        "Y_train = np.column_stack((omega_m_samples, h_samples))"
      ],
      "metadata": {
        "id": "N9MeqAmYJRmy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking shape of x and y\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('Y_train shape:', Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsJg7cOQQDQ-",
        "outputId": "18840f3f-88ec-4425-8cff-1cc0a280e394"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (10000, 100)\n",
            "Y_train shape: (10000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* X train is 5000 training examples of mu computed at 100 different redshifts\n",
        "* Y train is 5000 training examples of omega m and h at the respective mu(z)"
      ],
      "metadata": {
        "id": "x_sjvznbQS5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exporting this is a csv"
      ],
      "metadata": {
        "id": "HWXEqT8JQujx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "x_columns = [f'mu_z{i+1}' for i in range(X_train.shape[1])]\n",
        "df_X = pd.DataFrame(X_train, columns = x_columns)\n",
        "\n",
        "df_Y = pd.DataFrame(Y_train, columns = ['omega_m', 'h'])\n",
        "\n",
        "#combining\n",
        "training_examples = pd.concat([df_X,df_Y], axis = 1)\n",
        "\n",
        "#export as csv\n",
        "training_examples.to_csv('training_data.csv', index = False)"
      ],
      "metadata": {
        "id": "TtJv1RexQlz8"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}