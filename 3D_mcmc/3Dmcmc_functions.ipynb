{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsZB061kZGPHCWxbyCceeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephasal/cosmo_inference/blob/3-parameters/3D_mcmc/3Dmcmc_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file has all the code for the functions:\n",
        "\n",
        "* Distance modulus + fitting function\n",
        "* log likelihood and prior\n",
        "* basic & adaptive mcmc\n",
        "* Convergence via Gellman Rubin diagnostic\n",
        "* Autocorrelation\n",
        "* Effective sample size\n",
        "\n",
        "except that it is now in 4 dimensions to allow for $\\Omega_{\\Lambda}$ to be inferred as well $\\Omega_k$ to be calculauted at each step"
      ],
      "metadata": {
        "id": "9PbDtK1xUaUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to re write distance modulus, log prior, log likelihood and both basic and adaptive mcmc code"
      ],
      "metadata": {
        "id": "cmIxIWgFa1XE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distance modulus"
      ],
      "metadata": {
        "id": "6Zx0JfKAdfAN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ly4h19I8USan"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import quad\n",
        "\n",
        "def calculate_distance_modulus(z, omega_m, w, h):\n",
        "  \"\"\"\n",
        "  Calculates the dimensionless distance modulus using\n",
        "\n",
        "  inputs:\n",
        "  - z: redshift\n",
        "  - omega_m: density matter parameter\n",
        "  - w: dark energy equation of state parameter\n",
        "  - h: dimensionless hubble contant\n",
        "\n",
        "  outputs: theoretical distance modulus (mu_theoretical)\n",
        "\n",
        "  \"\"\"\n",
        "  c = 299792.458 # speed of light in km/s\n",
        "  H0 = 100 * h   #Hubble constant in km/s/Mpc\n",
        "\n",
        "  #Expansion rate\n",
        "  def expansion_rate(z, omega_m, w):\n",
        "    return np.sqrt(omega_m * (1+z)**3 +(1-omega_m) * (1+z)**(3*(1+w)))\n",
        "\n",
        "  #Comoving distance, using scipy integrate, couldnt find a well adopted fitting formula for non flat universe\n",
        "  def integrand(z, omega_m, w):\n",
        "    return 1/ expansion_rate(z, omega_m, w)\n",
        "\n",
        "  result, error = quad(integrand, 0, z, args = (omega_m, w)) #omega and w are fixed for each integration cycle\n",
        "  d_comoving = (c/H0) * result\n",
        "\n",
        "  # Transverse co moving distance\n",
        "  #based on curvature of universe this can be different\n",
        "\n",
        "  #Flat universe so comoving distance equals transverse co moving\n",
        "  d_M = d_comoving\n",
        "\n",
        "  #Luminosty distance\n",
        "  d_L = (1+z) * d_M\n",
        "\n",
        "  #Distance modulus\n",
        "  theoretical_mu = 25 + 5*np.log10(d_L)\n",
        "\n",
        "  return theoretical_mu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Likelihood and Prior"
      ],
      "metadata": {
        "id": "vRSM0ktknI0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Likelihood function, standard gaussian function\n",
        "\n",
        "def log_likelihood(mu_obs, mu_model, sigma_mu):\n",
        "\n",
        "  \"\"\"\n",
        "  Computes the logged likelihood for the sample and observed distance modulus\n",
        "\n",
        "  inputs:\n",
        "    - mu_obs: observed mu (mu from the data)\n",
        "    - mu_model: theoretical mu from the model\n",
        "    - sigma_mu: standard deviation of the observed mu (uncertainty)\n",
        "\n",
        "  outputs:\n",
        "    - log likelihood\n",
        "\n",
        "  \"\"\"\n",
        "  return -0.5 * np.sum((mu_obs - mu_model)**2/sigma_mu**2)\n",
        "\n",
        "\n",
        "\n",
        "# Defining the prior as a function\n",
        "def log_prior(params):\n",
        "  \"\"\"\n",
        "  Function that sets a uniform prior of the omega parameters and h, based off the planck data\n",
        "\n",
        "  \"\"\"\n",
        "  omega_m, w, h = params\n",
        "\n",
        "  if 0.1 < omega_m < 0.5 and -2.0 < w < -0.3 and 0.4 < h < 0.9:\n",
        "    return 0.0 #log of 1 is 0\n",
        "\n",
        "  else:\n",
        "    return -np.inf #acceptance probability is 0 if not in the priors upper and lower bounds\n"
      ],
      "metadata": {
        "id": "w13om8L8nMOw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic MCMC"
      ],
      "metadata": {
        "id": "KxBAu9FDqLcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metropolis Hastings algorithm\n",
        "\n",
        "def metropolis_hastings(likelihood, z, mu_obs, sigma_mu, n_steps, initial_params, step_size, burn_in, n_walkers):\n",
        "\n",
        "  \"\"\"\n",
        "  Perform basic MCMC to sample from the posterio\n",
        "\n",
        "  inputs:\n",
        "    - likelihood: function to compute the likelihood\n",
        "    - z: redshift\n",
        "    - mu_obs: observed mu\n",
        "    - sigma_mu: standard deviation of the observed mu\n",
        "    - n_steps: Number of steps for MCMC\n",
        "    - intial_params: initial guesses for [omega_m, w, h] for each walker, has to be array with rows = number of walkers\n",
        "    - step size: proposal step size for [omega_m, w, h]\n",
        "    - burn_in : percentage of chain to discard for the burn in period (given as a decimal)\n",
        "    - n_walkers: number of walkers that are sampling\n",
        "\n",
        "  outputs:\n",
        "    Array in shape of (steps after burn in , walker number, 3)\n",
        "    (3 for the number of parameters in order of omega_m, w, h)\n",
        "\n",
        "  \"\"\"\n",
        "  params = np.array(initial_params) #input as bracket so just make an array\n",
        "  samples = []\n",
        "  accepted_samples = np.zeros(n_walkers) #gonna use to calculate acceptance rate\n",
        "\n",
        "  for step in range (n_steps):\n",
        "    new_params = np.empty_like(params)   #empty array same size as intial parameters array, need to keep track of new paramters for each walker via matrix\n",
        "\n",
        "    #Do similar calulation for new parameters as before but just have to loop it for all walkers now\n",
        "    for i in range(n_walkers):\n",
        "\n",
        "      #Proposal\n",
        "      #guess for new parameters with a multivariate gaussian proposal distribution\n",
        "\n",
        "      #defining the step size for each parameter\n",
        "      sigma_omega_m = step_size[0]\n",
        "      sigma_w = step_size[1]\n",
        "      sigma_h = step_size[2]\n",
        "\n",
        "\n",
        "      #covariance matrix thing, with off diagonals (correlation between them = 0)\n",
        "      covariance_matrix = np.diag([sigma_omega_m**2, sigma_w**2, sigma_h**2])\n",
        "\n",
        "      #Drawing from this new proposal now for each walker/ walker i\n",
        "      proposed_params = params[i] + np.random.multivariate_normal(np.zeros(3), covariance_matrix)\n",
        "      omega_m_proposed, w_proposed, h_proposed = proposed_params\n",
        "\n",
        "      #Priors on omegas and h using the functions we defined earlier\n",
        "      log_prior_proposed = log_prior(proposed_params)\n",
        "\n",
        "      #If prior is -inf(when our funciton decides it is not in the bounds of our prior), then reject it\n",
        "      if np.isneginf(log_prior_proposed):\n",
        "        new_params[i] = params[i]\n",
        "        continue\n",
        "\n",
        "      #PROPOSED PARAMETERS\n",
        "      #Distance modulus, log likelihood and posterior\n",
        "      vectorised_distance_mod = np.vectorize(calculate_distance_modulus)\n",
        "      proposed_mu_model  = vectorised_distance_mod(z, proposed_params[0], proposed_params[1], proposed_params[2])\n",
        "      proposed_log_likelihood = log_likelihood(mu_obs, proposed_mu_model, sigma_mu)\n",
        "\n",
        "      #LLog posterior of the proposed params\n",
        "      proposed_log_posterior = proposed_log_likelihood + log_prior_proposed\n",
        "\n",
        "      #CURRENT PARAMETERS\n",
        "      #Distance modulus, log likelihood and posterior of current parameters, from earlier function\n",
        "      #Distance mod using the parameters at the ith walker, each parameter is a column\n",
        "      current_mu_model =  vectorised_distance_mod(z, params[i,0], params[i,1], params[i,2])\n",
        "      current_log_likelihood = log_likelihood(mu_obs, current_mu_model, sigma_mu)\n",
        "\n",
        "      #Log posterior is the sum of likelihood and prior\n",
        "      current_log_posterior = current_log_likelihood + log_prior(params[i])\n",
        "\n",
        "\n",
        "\n",
        "      #Acceptance probalility, based on the change of the current and proposed posteriors\n",
        "      delta_log_posterior = proposed_log_posterior - current_log_posterior\n",
        "\n",
        "\n",
        "\n",
        "      #Explicit overflow protection to stop any rogue values messing shit up\n",
        "      #If the difference in likelihoods is at max python limit, then accept the new proposal with probaiblity 1. Means new parameters are leng\n",
        "      if delta_log_posterior > 700:\n",
        "        acceptance_probability = 1.0\n",
        "\n",
        "      #If difference in likelihood is at min python limit, then dont accept the new proposal at all. Means new parameters are clapped\n",
        "      elif delta_log_posterior < -700:\n",
        "        acceptance_probability = 0.0\n",
        "\n",
        "      #If difference something else then we accept with probability below and randomly sample. Lets us explore parameter space\n",
        "      else:\n",
        "        acceptance_probability = min(1, np.exp(delta_log_posterior))\n",
        "\n",
        "\n",
        "      u = np.random.uniform(0,1) #set the randomness part of accept/ reject\n",
        "\n",
        "      #Accept proposed move\n",
        "      if u < acceptance_probability:\n",
        "        new_params[i] = proposed_params\n",
        "        accepted_samples[i] += 1\n",
        "      else:\n",
        "        new_params[i] = params[i] #chain doesnt move and retrys sampling\n",
        "\n",
        "    #Updating all the walkers at the same time, outside of the loop, do end of every loop\n",
        "    params = new_params.copy()\n",
        "    samples.append(params.copy())\n",
        "\n",
        "  #Acceptance ratio calculation\n",
        "  acceptance_ratio = accepted_samples/ n_steps\n",
        "  print(f\"MCMC carried out with {n_steps} steps, and acceptance ratio of each walker {acceptance_ratio}\")\n",
        "\n",
        "\n",
        "  #Number of samples to discard from the chain due to burn in\n",
        "  burned_chains = int(burn_in * n_steps) #keep integer\n",
        "  samples_post_burn = samples[burned_chains:] #use everything after the burn in number\n",
        "\n",
        "  return np.array(samples_post_burn)"
      ],
      "metadata": {
        "id": "A8pvxxUfq0Pe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptive MCMC"
      ],
      "metadata": {
        "id": "lR86KHMPyCg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptive metropolis hastings algorithm based of Haario etc al 2001\n",
        "\n",
        "def adaptive_metropolis_hastings(likelihood, z, mu_obs, sigma_mu, n_steps, initial_params, step_size, burn_in, n_walkers, update_interval, target_alpha, learning_rate):\n",
        "  \"\"\"\n",
        "  Perform Metropolis Hastings MCMC to sample from the posterior\n",
        "\n",
        "  inputs:\n",
        "    - likelihood: function to compute the likelihood\n",
        "    - z: redshift\n",
        "    - mu_obs: observed mu\n",
        "    - sigma_mu: standard deviation of the observed mu\n",
        "    - n_steps: Number of steps for MCMC\n",
        "    - intial_params: initial guesses for [omega_m, w, h] for each walker, has to be array with rows = number of walkers\n",
        "    - step size: proposal step size for [omega_m, w, h]\n",
        "    - burn_in : percentage of chain to discard for the burn in period (given as a decimal)\n",
        "    - n_walkers: number of walkers that are sampling\n",
        "    - update_interval: number of iterations to update the adaptive parameters\n",
        "    - target_alpha: target acceptance rate\n",
        "    - learning_rate: learning rate of the adaptation\n",
        "\n",
        "\n",
        "  outputs:\n",
        "    - Array in shape of (steps after burn in , walker number, 3)\n",
        "      (3 for the number of parameters in order of omega_m, w, h)\n",
        "    - Alpha all walkers: average acceptance rate of the whole thing\n",
        "    - History of covariance matricieis\n",
        "    - History of step sizes\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  params = np.array(initial_params) #input as [] so just make an array\n",
        "  samples = []\n",
        "  accepted_samples = np.zeros(n_walkers)  #gonna use to calculate acceptance rate\n",
        "\n",
        "  #New adaptive parameters\n",
        "  accepted_cycle = np.zeros(n_walkers) #empty array of accepted proposals at each cycle/iteration\n",
        "\n",
        "  #Proposal\n",
        "  #guess for new parameters, propsal distribution is a multivariate gaussian distribution now\n",
        "  #defining the step size for each parameter, step size has to be a 4x1 array\n",
        "  sigma_omega_m = step_size[0]\n",
        "  sigma_w = step_size[1]\n",
        "  sigma_h = step_size[2]\n",
        "\n",
        "\n",
        "  #Set up covariance matrix\n",
        "  #Intially set the off diagonals (correlation between the parameters) as 0\n",
        "  covariance_matrix = np.diag([sigma_omega_m**2, sigma_w, sigma_h**2])\n",
        "\n",
        "  #add smoothing parameter when updating the covariance matrix later, so that we dont just abruptly jump fully to the new one\n",
        "  smoothing = 0.2 #keeps 80% of the old covariance, can adjust this later\n",
        "\n",
        "  #Lists to store the history of the covariance and step size: used to test the pilot runs\n",
        "  cov_history = []\n",
        "  step_history = []\n",
        "\n",
        "  for step in range(n_steps):\n",
        "    new_params = np.empty_like(params) # empty array same size as initial parameters arry, need to keep track of each walker via matrix\n",
        "\n",
        "\n",
        "    #Do similar calculation for new parameters as before but just have to loop it for all walkers now\n",
        "    for i in range(n_walkers):\n",
        "\n",
        "      #drawing from new proposal now but for each walker/ walker i\n",
        "      proposed_params = params[i] + np.random.multivariate_normal(np.zeros(3), covariance_matrix)\n",
        "      omega_m_proposed, w_proposed, h_proposed = proposed_params\n",
        "\n",
        "      #Priors on the omegas and h using the function for prior\n",
        "      log_prior_proposed = log_prior(proposed_params)\n",
        "\n",
        "      #If prior is -inf(when our funciton decides it is not in the bounds of our prior), then reject it\n",
        "      if np.isneginf(log_prior_proposed):\n",
        "        new_params[i] = params[i]\n",
        "        continue\n",
        "\n",
        "      #PROPOSED PARAMETERS\n",
        "      #Distance modulus, log likelihood and posterior\n",
        "      vectorised_distance_mod = np.vectorize(calculate_distance_modulus)\n",
        "      proposed_mu_model  = vectorised_distance_mod(z, proposed_params[0], proposed_params[1], proposed_params[2])\n",
        "      proposed_log_likelihood = log_likelihood(mu_obs, proposed_mu_model, sigma_mu)\n",
        "\n",
        "      #LLog posterior of the proposed params\n",
        "      proposed_log_posterior = proposed_log_likelihood + log_prior_proposed\n",
        "\n",
        "      #CURRENT PARAMETERS\n",
        "      #Distance modulus, log likelihood and posterior of current parameters, from earlier function\n",
        "      #Distance mod using the parameters at the ith walker, each parameter is a column\n",
        "\n",
        "      current_mu_model =  vectorised_distance_mod(z, params[i,0], params[i,1], params[i,2])\n",
        "      current_log_likelihood = log_likelihood(mu_obs, current_mu_model, sigma_mu)\n",
        "\n",
        "      #Log posterior is the sum of likelihood and prior\n",
        "      current_log_posterior = current_log_likelihood + log_prior(params[i])\n",
        "\n",
        "\n",
        "\n",
        "      #Acceptance probalility, based on the change of the current and proposed posteriors\n",
        "      delta_log_posterior = proposed_log_posterior - current_log_posterior\n",
        "\n",
        "\n",
        "\n",
        "      #Explicit overflow protection to stop any rogue values messing shit up\n",
        "      #If the difference in likelihoods is at max python limit, then accept the new proposal with probaiblity 1. Means new parameters are leng\n",
        "      if delta_log_posterior > 700:\n",
        "        acceptance_probability = 1.0\n",
        "\n",
        "      #If difference in likelihood is at min python limit, then dont accept the new proposal at all. Means new parameters are clapped\n",
        "      elif delta_log_posterior < -700:\n",
        "        acceptance_probability = 0.0\n",
        "\n",
        "      #If difference something else then we accept with probability below and randomly sample. Lets us explore parameter space\n",
        "      else:\n",
        "        acceptance_probability = min(1, np.exp(delta_log_posterior))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      u = np.random.uniform(0,1) #set the randomness part of accept/ reject\n",
        "\n",
        "      #Accept proposed move\n",
        "      if u < acceptance_probability:\n",
        "        new_params[i] = proposed_params\n",
        "        accepted_samples[i] += 1\n",
        "        accepted_cycle[i] += 1 #also add acceptance count for each walker adaptation thing\n",
        "      else:\n",
        "        new_params[i] = params[i] #chain doesnt move and retrys sampling\n",
        "\n",
        "    #Updating all the walkers at the same time, outside of the loop, do end of every loop\n",
        "    params = new_params.copy()\n",
        "    samples.append(params.copy())\n",
        "\n",
        "    #Adaptive update of covariance after every update interval iteration loop\n",
        "    if (step +1) % update_interval == 0: #check if nth+1 iteration is exact multiple, so saying it has don 100/200/300 steps\n",
        "      average_acceptance = np.mean(accepted_cycle)/ update_interval #acceptance rate of this cycle (100 steps)\n",
        "\n",
        "      #Use the last update interval to calculate the variance\n",
        "      recent_window = samples[-update_interval:]\n",
        "      recent_samples = np.array(recent_window).reshape(-1,3) #make it 3d\n",
        "\n",
        "      #Calculate sample covariance and this then includes if there are any correlations between them in the off diagonals\n",
        "      sample_cov = np.cov(recent_samples, rowvar = False)\n",
        "      epsilon = 1e-6 #add this to stop any weird 0s messing up calculations\n",
        "      sample_cov += epsilon *np.eye(4)\n",
        "\n",
        "      #Scale covariance based on acceptance rate difference\n",
        "      #Increase covariance matrix if alpha larger than target, decrease if alpha is too small\n",
        "      #Robbins Munro approximation/ Haario et al.\n",
        "\n",
        "      scale_factor = np.exp(learning_rate * (average_acceptance - target_alpha))\n",
        "      new_covariance_matrix = sample_cov * scale_factor\n",
        "\n",
        "\n",
        "      #update the proposal covariance and then adjust step size using the sqrt of the diagonals of the covariance matrix\n",
        "      #Add smoothing to the update now\n",
        "      covariance_matrix = (1-smoothing) * covariance_matrix + smoothing * new_covariance_matrix\n",
        "\n",
        "      step_size = [np.sqrt(covariance_matrix[0,0]), np.sqrt(covariance_matrix[1,1]), np.sqrt(covariance_matrix[2,2]), np.sqrt(covariance_matrix[3,3])]\n",
        "\n",
        "      #Saving copies of the covariance and step size to look at when testing the pilot runs\n",
        "      cov_history.append(covariance_matrix.copy())\n",
        "      step_history.append(step_size.copy())\n",
        "\n",
        "      #Reset counter\n",
        "      accepted_cycle = np.zeros(n_walkers)\n",
        "\n",
        "  #Acceptance ratio calculation\n",
        "  acceptance_ratio = accepted_samples/ n_steps\n",
        "  print(f\"MCMC carried out with {n_steps} steps, and acceptance ratio of each walker {acceptance_ratio}\")\n",
        "\n",
        "   #Return avergae acceptance ratio of all the walkers\n",
        "  alpha_all_walkers = np.mean(acceptance_ratio)\n",
        "  #Number of samples to discard from the chain due to burn in\n",
        "  burned_chains = int(burn_in * n_steps) #keep integer\n",
        "  samples_post_burn = samples[burned_chains:] #use everything after the burn in number\n",
        "\n",
        "  return np.array(samples_post_burn), alpha_all_walkers, cov_history, step_history\n"
      ],
      "metadata": {
        "id": "jKEHi8UqrFiB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gelman Rubin Diagnostic"
      ],
      "metadata": {
        "id": "bikt1i-k5j6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gelman_rubin(chains):\n",
        "  \"\"\"\n",
        "  Function that uses the Gelman-Rubin diagnostic test for convergence, compares variance between multiple chains to the variance within each chain\n",
        "\n",
        "  input: 2d array of the chain for a particular parameter (rows = value of parameter at iteration, column = walker )\n",
        "\n",
        "  output: Estimate of R\n",
        "\n",
        "  \"\"\"\n",
        "  #Mean of each chain\n",
        "  chain_means = np.mean(chains, axis=0) #mean of parameters at each point\n",
        "\n",
        "\n",
        "  #Overall mean of all the chains across the whole thing\n",
        "  overall_mean = np.mean(chain_means)\n",
        "\n",
        "  #Between chain variance\n",
        "  n, m = chains.shape\n",
        "  B = (n/(m-1)) * np.sum((chain_means - overall_mean)**2) #lmao this was giving such a weird B value at first because it was summing before squaring, fixed with brackets now\n",
        "\n",
        "  #Average chain variance\n",
        "  W = 1/(m) * np.sum(np.var(chains, axis = 0, ddof = 1))\n",
        "\n",
        "  #Calculate V\n",
        "  V = ((n-1)/n) * W + ((m+1)/(m*n)) * B\n",
        "\n",
        "  #Calculate R\n",
        "  R = np.sqrt(V/W)\n",
        "\n",
        "  return R"
      ],
      "metadata": {
        "id": "DxPX1ROT5mVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autocorrelation"
      ],
      "metadata": {
        "id": "1BHadILK50wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def autocorrelation(x, lag):\n",
        "\n",
        "  \"\"\"\n",
        "  Calulcated the autocorrelation of array x at a given lag k\n",
        "  Auto correlation is covariance(X,Y) over standard deviation\n",
        "  \"\"\"\n",
        "  n = len(x)\n",
        "  if n <= lag:\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "  covariance = np.sum((x[:n-lag] - np.mean(x)) * (x[lag:] - np.mean(x)))\n",
        "\n",
        "  std = np.sum((x - np.mean(x))**2)\n",
        "  if std == 0:\n",
        "    return np.nan\n",
        "\n",
        "  return covariance/std\n"
      ],
      "metadata": {
        "id": "d_2km2mK5rwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Effective sample size"
      ],
      "metadata": {
        "id": "rNFfzoJF56d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eff_sample_size(chain):\n",
        "  \"\"\"\n",
        "  Calculates effective sample size, estimate of sample size that is not related\n",
        "\n",
        "  inputs: chain of samples from mcmc\n",
        "\n",
        "  outputs: effective sample size, number\n",
        "  \"\"\"\n",
        "  #Need to do N divided by sum of lag from -inf to inf which simplifies to 1+2* of lag from 1 to T (first odd positive intger for which autocorrelation of that t+1 and t+2 are negative)\n",
        "  #From chapter 11 in BDA3\n",
        "  #just gonna use N//2 which is a common implementation for the sum\n",
        "\n",
        "  N = len(chain)\n",
        "\n",
        "  rho_sum = 0\n",
        "  previous_rho = 0\n",
        "  for i in range(1,N//2):\n",
        "    rho_t = autocorrelation(chain, i)\n",
        "    if np.isnan(rho_t):\n",
        "      continue\n",
        "\n",
        "    #Stop summing when pt+1 and pt+2 are negative\n",
        "    if i > 1 and (rho_t + previous_rho) < 0:\n",
        "      break\n",
        "\n",
        "    rho_sum += rho_t\n",
        "    previous_rho = rho_t #to go loop back for the comparison\n",
        "\n",
        "  ess = N / (1 + 2 * rho_sum)\n",
        "\n",
        "  return ess\n",
        "\n",
        "#Well turns out this only does it for one chain rip, but i can use it to calculaurte all the chains ess shown in the next cell\n",
        "\n",
        "#real ess calculator\n",
        "\n",
        "def eff_sample_size_multichain(chains):\n",
        "\n",
        "  \"\"\"\n",
        "  Calculated the total effective sample size by using all the chains this time\n",
        "\n",
        "  Inputs:\n",
        "  chains: array in the shape of (iterations, n_walker)\n",
        "\n",
        "  outputs:\n",
        "  total_ess: a number that says the mean of effective sample size of all the chains\n",
        "  \"\"\"\n",
        "  n_chains = chains.shape[1] #y column of chains array\n",
        "  ess_values = [eff_sample_size(chains[:,i]) for i in range(n_chains)] #calculate ess for each chain\n",
        "  total_ess = sum(ess_values) #add up all the chains ess to get one big final ess\n",
        "  return total_ess"
      ],
      "metadata": {
        "id": "t6HG9nmG56QK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}